{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical-11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-esAA94IfiO"
      },
      "source": [
        "**Implement HMM/CRF on sequence tagging task**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjL-orO-UYR1",
        "outputId": "9202483d-3a2c-4ed8-f5c7-7b299c6fc046"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('corpus')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Error loading corpus: Package 'corpus' not found in index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOPpXTaPN3al",
        "outputId": "f1385da3-b12c-43d6-abcf-795e4ff47c3e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89IrM9dENpzz",
        "outputId": "e1363128-a148-4348-eba8-384a74e8dac9"
      },
      "source": [
        "nltk.download('universal_tagset')\n",
        "\n",
        "from nltk.corpus import treebank,brown\n",
        "\n",
        "corpus = brown.tagged_sents(tagset='universal')[:-100] \n",
        "#print(corpus[0])\n",
        "tag_dict={}\n",
        "word_dict={}\n",
        "\n",
        "for sent in corpus:\n",
        "    for elem in sent:\n",
        "        w = elem[0]\n",
        "        tag= elem[1]\n",
        "        if w not in word_dict:\n",
        "            word_dict[w]=0\n",
        "        if tag not in tag_dict:\n",
        "            tag_dict[tag]=0\n",
        "        word_dict[w]+=1\n",
        "        tag_dict[tag]+=1\n",
        "\n",
        "print('Number of words(M): ',len(word_dict))\n",
        "print('Number of tags(N): ',len(tag_dict))\n",
        "print(tag_dict)\n",
        "        \n",
        "test_data= brown.tagged_sents(tagset='universal')[-10:]\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "Number of words(M):  55907\n",
            "Number of tags(N):  12\n",
            "{'DET': 136724, 'NOUN': 275075, 'ADJ': 83581, 'VERB': 182380, 'ADP': 144483, '.': 147231, 'ADV': 56115, 'CONJ': 38067, 'PRT': 29759, 'PRON': 49174, 'NUM': 14853, 'X': 1369}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "860WFgi9N_0s",
        "outputId": "58144104-63b1-4aa7-ed74-61c3958ec3a3"
      },
      "source": [
        "brown_tags_words = [ ]\n",
        "for sent in corpus:  \n",
        "    brown_tags_words.append( (\"START\", \"START\") )\n",
        "    brown_tags_words.extend([ (tag, word) for (word, tag) in sent ])\n",
        "    brown_tags_words.append( (\"END\", \"END\") )\n",
        "    \n",
        "print(brown_tags_words[0:30])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('START', 'START'), ('DET', 'The'), ('NOUN', 'Fulton'), ('NOUN', 'County'), ('ADJ', 'Grand'), ('NOUN', 'Jury'), ('VERB', 'said'), ('NOUN', 'Friday'), ('DET', 'an'), ('NOUN', 'investigation'), ('ADP', 'of'), ('NOUN', \"Atlanta's\"), ('ADJ', 'recent'), ('NOUN', 'primary'), ('NOUN', 'election'), ('VERB', 'produced'), ('.', '``'), ('DET', 'no'), ('NOUN', 'evidence'), ('.', \"''\"), ('ADP', 'that'), ('DET', 'any'), ('NOUN', 'irregularities'), ('VERB', 'took'), ('NOUN', 'place'), ('.', '.'), ('END', 'END'), ('START', 'START'), ('DET', 'The'), ('NOUN', 'jury')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJpJT1GOOHRL",
        "outputId": "1d43d560-0745-4a3e-fa08-738d2a392880"
      },
      "source": [
        "CFD_tag_words = nltk.ConditionalFreqDist(brown_tags_words)\n",
        "CPD_tag_words = nltk.ConditionalProbDist(CFD_tag_words, nltk.MLEProbDist)\n",
        "\n",
        "brown_tags = [tag for (tag, word) in brown_tags_words ]\n",
        "\n",
        "CFD_tags= nltk.ConditionalFreqDist(nltk.bigrams(brown_tags))\n",
        "\n",
        "CPD_tags = nltk.ConditionalProbDist(CFD_tags, nltk.MLEProbDist)\n",
        "\n",
        "tag_trans_matrix=[]\n",
        "j=-1\n",
        "for tag1 in tag_dict:\n",
        "    tag_trans_matrix.append([])\n",
        "    j=j+1\n",
        "    for tag2 in tag_dict:\n",
        "        tag_trans_matrix[j].append(CPD_tags[tag1].prob(tag2))\n",
        "print(\"State Transition matrix:\")\n",
        "print(tag_trans_matrix)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State Transition matrix:\n",
            "[[0.005917029928907872, 0.6263860039203066, 0.23980427723004008, 0.06470700096544864, 0.009091308036628536, 0.012748310464878149, 0.017502413621602646, 0.0006436324273719318, 0.002011351335537287, 0.009895848570843451, 0.009764196483426465, 0.0013969749275913519], [0.01550122693810779, 0.14934835953830775, 0.012894665091338726, 0.1589093883486322, 0.24437698809415614, 0.2835844769608289, 0.026370989730073617, 0.0596782695628465, 0.01782786512769245, 0.01978369535581205, 0.008077796964464238, 0.0003308188675815687], [0.005850611981191898, 0.65281583134923, 0.05690288462688889, 0.01746808485182039, 0.08844115289360022, 0.10033380792285328, 0.009643339993539201, 0.037604240198131154, 0.019286679987078403, 0.003804692454026633, 0.006987233940728156, 0.0004905421088524905], [0.16292904923785503, 0.0975710055927185, 0.05753920386007238, 0.1843020067989911, 0.1691797346200241, 0.08060642614321746, 0.10326241912490404, 0.014376576378988924, 0.06559381511130606, 0.054923785502796356, 0.008975764886500712, 0.00018094089264173704], [0.4555968522248292, 0.25848023642919926, 0.08268792868365137, 0.041257448973235605, 0.020293044856488307, 0.0097450911179862, 0.015489711592367268, 0.0018894956500072673, 0.014230047825695757, 0.06968985970667829, 0.03013503318729539, 0.000449879916668397], [0.0677031331716826, 0.08292411244914454, 0.028920539831964735, 0.07657354769036412, 0.06516290726817042, 0.10723964382500968, 0.043564195040446646, 0.06929926442121565, 0.018331737202083802, 0.046247053949236235, 0.012076261113488328, 0.001256528856015377], [0.07361668003207698, 0.032861088835427245, 0.13622026196204223, 0.24031007751937986, 0.14204758086073244, 0.17000801924619086, 0.09687249398556536, 0.017321571772253408, 0.028655439721999465, 0.048329323710237904, 0.013311948676824378, 8.910273545397844e-05], [0.1511282738329787, 0.24380697191793416, 0.11211810754721938, 0.19536606509575222, 0.07334436651167678, 0.02075288307457903, 0.09136522447264034, 0.0002626947224630257, 0.02503480705072635, 0.06753881314524392, 0.01867759476712113, 0.000551658917172354], [0.08363856312376088, 0.03578749285930307, 0.018918646459894484, 0.6225007560737928, 0.09066164857690111, 0.07658187439094055, 0.036123525656104036, 0.012231593803555227, 0.01125709869283242, 0.0068214657750596455, 0.00510769851137471, 6.720655936019356e-05], [0.0175499247569854, 0.008886810102899906, 0.00951722454955871, 0.7064098914060276, 0.0555781510554358, 0.10357099280107374, 0.05403261886362712, 0.01142880383942734, 0.023752389474112335, 0.008195387806564444, 0.0009761255948265344, 0.0], [0.013128660876590587, 0.38025988015889045, 0.05917996364370834, 0.04551269103884737, 0.1310846293678045, 0.2710563522520703, 0.02039991920824076, 0.038308759173231, 0.005251464350636235, 0.008483134720258533, 0.021746448528916718, 0.00020197939810139365], [0.005113221329437546, 0.0547845142439737, 0.0029218407596785976, 0.052593133674214754, 0.053323593864134405, 0.2731921110299489, 0.006574141709276844, 0.022644265887509132, 0.007304601899196494, 0.006574141709276844, 0.0007304601899196494, 0.5127830533235939]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UXA-E-3OOjS"
      },
      "source": [
        "def Viterbi(sentence):\n",
        "    sentlen = len(sentence)\n",
        "    distinct_tags = set(brown_tags)\n",
        "\n",
        "    viterbi = [ ]\n",
        "    backpointer = [ ]\n",
        "\n",
        "    viterbi_init = { }\n",
        "    backpointer_init = { }\n",
        "\n",
        "    for tag in distinct_tags:\n",
        "        if tag == \"START\": continue\n",
        "        viterbi_init[ tag ] = CPD_tags[\"START\"].prob(tag) * CPD_tag_words[tag].prob(sentence[0])\n",
        "        backpointer_init[ tag ] = \"START\"\n",
        "    viterbi.append(viterbi_init)\n",
        "    backpointer.append(backpointer_init)\n",
        "\n",
        "    for wordindex in range(1, len(sentence)):\n",
        "        cur_viterbi = { }\n",
        "        cur_backpointer = { }\n",
        "        prev_viterbi = viterbi[-1]\n",
        "            \n",
        "        for tag in distinct_tags:\n",
        "            if tag == \"START\": continue\n",
        "            if sentence[wordindex] not in word_dict.keys():\n",
        "                best_prevtag = max(prev_viterbi.keys(),key = lambda prevtag: \\\n",
        "                    prev_viterbi[ prevtag ] * CPD_tags[prevtag].prob(tag) *0.0001)\n",
        "                cur_viterbi[tag] = prev_viterbi[ best_prevtag ] *\\\n",
        "                                    CPD_tags[best_prevtag].prob(tag) * 0.0001\n",
        "            else:\n",
        "                best_prevtag = max(prev_viterbi.keys(),key = lambda prevtag: \\\n",
        "                    prev_viterbi[ prevtag ] * CPD_tags[prevtag].prob(tag) * \n",
        "                                    CPD_tag_words[tag].prob(sentence[wordindex]))\n",
        "                cur_viterbi[tag] = prev_viterbi[ best_prevtag ] *\\\n",
        "                                    CPD_tags[best_prevtag].prob(tag) *\\\n",
        "                                    CPD_tag_words[tag].prob(sentence[wordindex])\n",
        "            cur_backpointer[tag] = best_prevtag\n",
        "\n",
        "        viterbi.append(cur_viterbi)\n",
        "        backpointer.append(cur_backpointer)\n",
        "\n",
        "    prev_viterbi = viterbi[-1]\n",
        "    best_prevtag = max(prev_viterbi.keys(),key = lambda prevtag: prev_viterbi[ prevtag ] *\\\n",
        "                       CPD_tags[prevtag].prob(\"END\"))\n",
        "\n",
        "    prob_best_seq = prev_viterbi[ best_prevtag ] * CPD_tags[ best_prevtag].prob(\"END\")\n",
        "    best_tag_seq = [ \"END\", best_prevtag ]\n",
        "\n",
        "    backpointer.reverse()\n",
        "    current_best_tag = best_prevtag\n",
        "    for bp in backpointer:\n",
        "        best_tag_seq.append(bp[current_best_tag])\n",
        "        current_best_tag = bp[current_best_tag]\n",
        "\n",
        "    best_tag_seq.reverse()\n",
        "    \n",
        "    return best_tag_seq[1:-1]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQiHTCHBOY03",
        "outputId": "c3a35b40-7c00-431a-9a5c-78c04a7dcdc3"
      },
      "source": [
        "sentence = ['Hi','there','these','are','college','practicals', '.']\n",
        "\n",
        "tag_seq=Viterbi(sentence)\n",
        "print(\"\\nThe given sentence:\",sentence)\n",
        "print(\"\\nThe POS tags:\",tag_seq)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The given sentence: ['Hi', 'there', 'these', 'are', 'college', 'practicals', '.']\n",
            "\n",
            "The POS tags: ['PRT', 'PRT', 'DET', 'VERB', 'NOUN', 'NOUN', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G103Ng9CO9sz",
        "outputId": "073ad84e-faab-404e-f238-4d49e907205b"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_list=[]\n",
        "y_true=[]\n",
        "y_pred=[]\n",
        "i=-1\n",
        "for sent in test_data:\n",
        "    test_list.append([])\n",
        "    i=i+1\n",
        "    for elem in sent:\n",
        "        test_list[i].append(elem[0])\n",
        "        y_true.append(elem[1])\n",
        "        \n",
        "print(test_list[0])\n",
        "        \n",
        "print(\"\\nActual tags:\")\n",
        "print(\"************\")\n",
        "print(y_true)\n",
        "\n",
        "for sent in test_list:\n",
        "    y_pred=y_pred+Viterbi(sent)\n",
        "    \n",
        "print(\"\\nPredicted tags:\")\n",
        "print(\"************\")\n",
        "print(y_pred)\n",
        "print(\"\\nTotal testing accuracy: \",accuracy_score(y_true, y_pred))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['you', \"can't\", 'very', 'well', 'sidle', 'up', 'to', 'people', 'on', 'the', 'street', 'and', 'ask', 'if', 'they', 'want', 'to', 'buy', 'a', 'hot', 'Bodhisattva', '.']\n",
            "\n",
            "Actual tags:\n",
            "************\n",
            "['PRON', 'VERB', 'ADV', 'ADV', 'VERB', 'ADP', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'PRON', 'VERB', 'PRT', 'VERB', 'DET', 'ADJ', 'NOUN', '.', 'ADV', '.', 'ADP', 'PRT', 'VERB', 'PRT', 'VERB', 'X', 'X', 'X', 'ADV', 'ADV', 'ADP', 'NOUN', '.', 'NOUN', '.', 'NOUN', 'NOUN', '.', 'DET', 'NOUN', 'NOUN', '.', 'NOUN', 'NOUN', '.', 'NOUN', '.', 'CONJ', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'PRT', 'VERB', '.', 'PRON', 'VERB', 'VERB', 'PRT', 'VERB', 'VERB', 'ADV', '.', 'DET', 'NOUN', '.', 'ADP', 'PRON', 'VERB', 'ADJ', 'ADV', 'PRT', 'VERB', 'DET', 'NOUN', '.', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'PRT', 'VERB', 'ADP', 'DET', 'ADJ', '.', 'VERB', 'PRON', 'PRT', '.', 'PRT', 'NOUN', 'CONJ', 'DET', 'NOUN', '.', 'ADP', 'PRON', 'VERB', 'VERB', 'ADP', 'PRON', 'PRT', 'VERB', 'DET', 'ADJ', '.', 'ADV', 'PRON', '.', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'ADP', 'PRON', 'VERB', 'ADP', 'DET', 'NOUN', 'CONJ', '.', 'VERB', '.', 'VERB', 'PRT', 'ADP', 'DET', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'NOUN', '.', 'PRON', 'VERB', 'DET', 'VERB', 'NOUN', 'CONJ', 'DET', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', '.', 'ADJ', '.', 'PRON', 'VERB', 'DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'CONJ', 'DET', 'NOUN', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'NOUN', '.', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADV', 'ADJ', '.', 'ADP', 'DET', 'PRON', 'VERB', 'ADJ', 'ADP', 'NOUN', 'ADP', 'DET', 'ADJ', '.', 'ADJ', 'NOUN', '.', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'VERB', 'VERB', '.']\n",
            "\n",
            "Predicted tags:\n",
            "************\n",
            "['PRON', 'VERB', 'ADV', 'ADV', 'VERB', 'PRT', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'PRON', 'VERB', 'PRT', 'VERB', 'DET', 'ADJ', 'NOUN', '.', 'ADV', '.', 'ADP', 'PRT', 'VERB', 'PRT', 'VERB', 'DET', 'X', 'VERB', 'ADV', 'ADV', 'ADP', 'NOUN', '.', 'NOUN', '.', 'NOUN', 'NOUN', '.', 'DET', 'NOUN', 'VERB', '.', 'NOUN', 'NOUN', '.', 'NOUN', '.', 'CONJ', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'PRT', 'VERB', '.', 'PRON', 'VERB', 'VERB', 'PRT', 'VERB', 'VERB', 'ADV', '.', 'DET', 'NOUN', '.', 'ADP', 'PRON', 'VERB', 'ADV', 'ADV', 'PRT', 'VERB', 'DET', 'NOUN', '.', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'PRT', 'VERB', 'ADP', 'DET', 'ADJ', '.', 'VERB', 'PRON', 'PRT', '.', 'PRT', 'NOUN', 'CONJ', 'DET', 'NOUN', '.', 'ADP', 'PRON', 'VERB', 'VERB', 'ADP', 'PRON', 'PRT', 'VERB', 'DET', 'ADJ', '.', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', '.', 'NOUN', 'ADP', 'DET', 'NOUN', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'ADP', 'PRON', 'VERB', 'ADP', 'DET', 'NOUN', 'CONJ', '.', 'NOUN', '.', 'VERB', 'PRT', 'ADP', 'DET', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'NOUN', '.', 'PRON', 'VERB', 'DET', 'NOUN', 'NOUN', 'CONJ', 'DET', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', '.', 'NOUN', '.', 'PRON', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'CONJ', 'DET', 'NOUN', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'NOUN', '.', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADV', 'ADJ', '.', 'ADP', 'DET', 'PRON', 'VERB', 'ADJ', 'ADP', 'NOUN', 'ADP', 'DET', 'ADJ', '.', 'ADJ', 'NOUN', '.', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'VERB', 'NOUN', '.']\n",
            "\n",
            "Total testing accuracy:  0.9330543933054394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNSmvSaaPDYt"
      },
      "source": [
        "# It is using viterbe\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}